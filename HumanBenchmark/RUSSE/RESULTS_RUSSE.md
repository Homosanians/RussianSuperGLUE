# RUSSE

Our Russe dataset:

test  18891 examples

dev   8505 examples

train 19845 examples

## Human benchmark

For human benchmark about 4685 examples verified in Toloka.


Overlap 5

12 bad annotators were excluded (0.5 threshold)


Accuracy: 0.781


```
				precision    recall  f1-score   support

       false       0.87      0.71      0.78       335
        true       0.71      0.87      0.78       268

    accuracy                           0.78       603
   macro avg       0.79      0.79      0.78       603
weighted avg       0.80      0.78      0.78       603
```
